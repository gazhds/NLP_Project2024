{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "479d386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from datasets import load_metric\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b986cf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TRAIN = \"C:/Users/kelis/ITU/Year_2/4th_semester/NLP/project/scripts/NLP_project2024-main/train.bio\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9ae059",
   "metadata": {},
   "source": [
    "### Functions to read and preprocess data before perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72e9e510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'B-ORG': 1, 'B-PER': 2, 'B-LOC': 3, 'I-PER': 4, 'B-MISC': 5, 'I-ORG': 6, 'I-MISC': 7, 'I-LOC': 8}\n"
     ]
    }
   ],
   "source": [
    "def read_bio_file(path):\n",
    "    \n",
    "    data = []\n",
    "    current_words = []\n",
    "    current_tags = []\n",
    "\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()[2:]\n",
    "        \n",
    "    for line in lines:\n",
    "        \n",
    "        line = line.strip()\n",
    "        \n",
    "        if line: # if line is not an empty line\n",
    "            tok = line.split('\\t')\n",
    "            current_words.append(tok[0])\n",
    "            current_tags.append(tok[3])\n",
    "            \n",
    "        else:\n",
    "            if current_words:\n",
    "                data.append((current_words, current_tags))\n",
    "            current_words = []\n",
    "            current_tags = []\n",
    "            \n",
    "            \n",
    "    if current_tags != []:\n",
    "        data.append((current_words, current_tags))\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['words', 'tags'])\n",
    "    df['id'] = df.index\n",
    "    df = df[['id', 'words', 'tags']]\n",
    "    \n",
    "    return df\n",
    "\n",
    "class Vocab():\n",
    "    def __init__(self, pad_unk='<PAD>'):\n",
    "        self.pad_unk = pad_unk\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = []\n",
    "\n",
    "    def getIdx(self, word, add=False):\n",
    "        if word is None or word == self.pad_unk:\n",
    "            return None\n",
    "        if word not in self.word2idx:\n",
    "            if add:\n",
    "                idx = len(self.idx2word)\n",
    "                self.word2idx[word] = idx\n",
    "                self.idx2word.append(word)\n",
    "                return idx\n",
    "            else:\n",
    "                return None\n",
    "        return self.word2idx[word]\n",
    "\n",
    "    def getWord(self, idx):\n",
    "        return self.idx2word[idx]\n",
    "\n",
    "label_indices = Vocab()\n",
    "tags_column = train_data[\"tags\"]\n",
    "\n",
    "for tags in tags_column:\n",
    "    for tag in tags:\n",
    "        label_indices.getIdx(tag, add=True)\n",
    "\n",
    "print(label_indices.word2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a92d4eb",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5db42a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>words</th>\n",
       "      <th>tags</th>\n",
       "      <th>tag_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[RT, @USER2362, :, Farmall, Heart, Of, The, Ho...</td>\n",
       "      <td>[O, O, O, B-ORG, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[#Volunteers, are, key, members, of, #CHEO’s, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[@USER2092, is, n't, it, funny, how, that, alw...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[RT, @USER80, :, Silence, is, better, than, li...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[I, just, spent, twenty, minutes, trying, to, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              words  \\\n",
       "0   0  [RT, @USER2362, :, Farmall, Heart, Of, The, Ho...   \n",
       "1   1  [#Volunteers, are, key, members, of, #CHEO’s, ...   \n",
       "2   2  [@USER2092, is, n't, it, funny, how, that, alw...   \n",
       "3   3  [RT, @USER80, :, Silence, is, better, than, li...   \n",
       "4   4  [I, just, spent, twenty, minutes, trying, to, ...   \n",
       "\n",
       "                                                tags  \\\n",
       "0  [O, O, O, B-ORG, O, O, O, O, O, O, O, O, O, O,...   \n",
       "1  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "2                  [O, O, O, O, O, O, O, O, O, O, O]   \n",
       "3                        [O, O, O, O, O, O, O, O, O]   \n",
       "4   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                             tag_idx  \n",
       "0  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "3                        [0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "4   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = read_bio_file(PATH_TRAIN)\n",
    "\n",
    "train_data['tag_idx'] = train_data['tags'].apply(lambda x: [label_indices.word2idx[tag] for tag in x])\n",
    "\n",
    "model_checkpoint = \"distilbert/distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, padding=True)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02521f79",
   "metadata": {},
   "source": [
    "### Helper functions for the insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f3750c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alphabet_list():\n",
    "        \n",
    "    # loops through the ascii codes of all lower case english letters\n",
    "    # and makes a list of the characters corresponding to those codes\n",
    "    return [chr(ascii_code) for ascii_code in range(ord(\"a\"), ord(\"z\")+1)]\n",
    "\n",
    "def insert_at_idx(word, letter, idx):\n",
    "\n",
    "    new_str = \"\" \n",
    "    new_str += word[:idx] + letter + word[idx:] #insert chosen letter at chosen index\n",
    "    \n",
    "    return new_str\n",
    "\n",
    "def insert_letter(word, seed=456):\n",
    "    \n",
    "    random.seed(seed) #set seed for reproducibility\n",
    "    \n",
    "    insert_at = random.randint(0, len(word)) #choose a random index in the word to insert at\n",
    "    # note: random.randint(start,end) is a closed interval so it takes the \"end\" number as well\n",
    "    \n",
    "    alph = get_alphabet_list()\n",
    "    letter = random.choice(alph) #choose a random english alphabet letter to be inserted\n",
    "    \n",
    "    print(f\"word {word} insert letter {letter} at idx {insert_at} (seed {seed})\")\n",
    "    \n",
    "    new_str = insert_at_idx(word, letter, insert_at) #insert chosen letter at chosen index\n",
    "    \n",
    "    return new_str\n",
    "\n",
    "def insert_multiple_letters(word, N, seed=456, set_seed=False, prints=False):\n",
    "    \n",
    "    if set_seed:\n",
    "        random.seed(seed) #set seed for reproducibility\n",
    "    \n",
    "    alph = get_alphabet_list()\n",
    "    letters = [random.choice(alph) for i in range(N)] # choose N random letters from\n",
    "    # the english alphabet to insert at the chosen indices\n",
    "    \n",
    "    if prints:\n",
    "        print(f\"word {word} | (seed {seed})\")\n",
    "        print(f\"Letters to insert: {letters}\")\n",
    "    \n",
    "    new_str = word\n",
    "\n",
    "    for i in range(N):\n",
    "        \n",
    "        chosen_idx = random.randint(0, len(new_str)) # choose a random index to insert at\n",
    "        if prints:\n",
    "            print(f\"Inserting letter {letters[i]} at index {chosen_idx} of word {new_str}\")\n",
    "        new_str = insert_at_idx(new_str, letters[i], chosen_idx) # update the word with the chosen insertion\n",
    "    \n",
    "    return new_str\n",
    "\n",
    "def perturb_sentence(sent, perturb_func, perc, seed=456, set_seed=False):\n",
    "    \n",
    "    n_words = int(perc * len(sent))\n",
    "    if n_words == 0:\n",
    "        return sent\n",
    "    \n",
    "    if set_seed:\n",
    "        random.seed(seed) #set seed for reproducibility\n",
    "    \n",
    "    new_sent = sent.copy()\n",
    "    \n",
    "    idxs = [x for x in random.sample(list(range(len(sent))), n_words)]\n",
    "    \n",
    "    for idx in idxs:\n",
    "        new_sent[idx] = perturb_func(new_sent[idx], n_words)\n",
    "        \n",
    "    return new_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f880f2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_dataset(data, perturb_func, perc_sents, perc_words, prints=False, seed=456, set_seed=False):\n",
    "    \n",
    "    n_sents = int(perc_sents * train_data.shape[0])\n",
    "    if set_seed:\n",
    "        random.seed(seed) #set seed for reproducibility\n",
    "    \n",
    "    new_data = data.copy()\n",
    "    \n",
    "    idxs = [x for x in random.sample(list(range(n_sents)), n_sents)]\n",
    "    print(idxs)\n",
    "    \n",
    "    for idx in idxs:\n",
    "        \n",
    "        if prints:\n",
    "            print(f\"Perturbing sentence idx {idx} | Original: \")\n",
    "            print(data[\"words\"][idx])\n",
    "            \n",
    "        new_sent = (perturb_sentence((new_data[\"words\"][idx]).copy(), perturb_func, perc_words)).copy()\n",
    "        new_data[\"words\"][idx] = new_sent\n",
    "        \n",
    "        if prints:\n",
    "            print(f\"Perturbed version:\")\n",
    "            print(new_data[\"words\"][idx])\n",
    "        \n",
    "            print(data[\"words\"][idx] == new_data[\"words\"][idx])\n",
    "        \n",
    "    return len(idxs), idxs, new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1297f650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[275, 103, 86, 228, 97, 14, 152, 257, 243, 156, 262, 187, 194, 40, 115, 110, 265, 172, 140, 21, 155, 293, 185, 30, 236, 197, 295, 196, 4, 74, 241, 300, 232, 204, 313, 159, 53, 177, 24, 326, 234, 163, 88, 25, 207, 56, 189, 218, 301, 296, 31, 179, 85, 71, 48, 3, 6, 139, 256, 190, 230, 304, 252, 323, 260, 255, 251, 77, 160, 108, 60, 220, 67, 186, 161, 20, 138, 312, 199, 36, 93, 247, 65, 266, 233, 267, 318, 168, 290, 250, 66, 146, 305, 72, 62, 183, 130, 222, 38, 264, 157, 285, 319, 80, 44, 129, 132, 324, 52, 299, 317, 136, 70, 151, 310, 98, 297, 206, 26, 17, 94, 153, 274, 202, 289, 209, 244, 208, 259, 178, 131, 133, 200, 203, 162, 246, 282, 81, 128, 188, 91, 195, 41, 311, 78, 182, 120, 214, 142, 248, 279, 105, 205, 126, 239, 210, 211, 240, 12, 309, 87, 298, 54, 102, 7, 35, 227, 79, 2, 0, 242, 96, 22, 121, 320, 258, 191, 224, 43, 134, 125, 112, 231, 46, 137, 1, 68, 281, 219, 111, 175, 106, 270, 47, 180, 27, 42, 5, 216, 100, 254, 57, 122, 59, 104, 23, 307, 245, 170, 11, 15, 223, 225, 117, 217, 119, 73, 321, 64, 10, 271, 315, 63, 114, 294, 143, 39, 291, 116, 261, 308, 314, 113, 34, 303, 28, 287, 109, 213, 280, 154, 235, 237, 173, 141, 171, 316, 18, 322, 167, 226, 198, 325, 249, 164, 212, 19, 61, 277, 238, 51, 149, 158, 253, 268, 193, 16, 284, 288, 176, 292, 263, 45, 169, 166, 123, 55, 32, 145, 181, 29, 276, 283, 84, 269, 92, 201, 69, 221, 174, 33, 107, 306, 101, 302, 50, 13, 273, 278, 82, 286, 9, 89, 58, 99, 95, 49, 144, 215, 76, 127, 75, 118, 165, 8, 229, 83, 150, 124, 148, 147, 192, 272, 184, 135, 37, 90]\n",
      "327\n",
      "[275, 103, 86, 228, 97, 14, 152, 257, 243, 156, 262, 187, 194, 40, 115, 110, 265, 172, 140, 21, 155, 293, 185, 30, 236, 197, 295, 196, 4, 74, 241, 300, 232, 204, 313, 159, 53, 177, 24, 326, 234, 163, 88, 25, 207, 56, 189, 218, 301, 296, 31, 179, 85, 71, 48, 3, 6, 139, 256, 190, 230, 304, 252, 323, 260, 255, 251, 77, 160, 108, 60, 220, 67, 186, 161, 20, 138, 312, 199, 36, 93, 247, 65, 266, 233, 267, 318, 168, 290, 250, 66, 146, 305, 72, 62, 183, 130, 222, 38, 264, 157, 285, 319, 80, 44, 129, 132, 324, 52, 299, 317, 136, 70, 151, 310, 98, 297, 206, 26, 17, 94, 153, 274, 202, 289, 209, 244, 208, 259, 178, 131, 133, 200, 203, 162, 246, 282, 81, 128, 188, 91, 195, 41, 311, 78, 182, 120, 214, 142, 248, 279, 105, 205, 126, 239, 210, 211, 240, 12, 309, 87, 298, 54, 102, 7, 35, 227, 79, 2, 0, 242, 96, 22, 121, 320, 258, 191, 224, 43, 134, 125, 112, 231, 46, 137, 1, 68, 281, 219, 111, 175, 106, 270, 47, 180, 27, 42, 5, 216, 100, 254, 57, 122, 59, 104, 23, 307, 245, 170, 11, 15, 223, 225, 117, 217, 119, 73, 321, 64, 10, 271, 315, 63, 114, 294, 143, 39, 291, 116, 261, 308, 314, 113, 34, 303, 28, 287, 109, 213, 280, 154, 235, 237, 173, 141, 171, 316, 18, 322, 167, 226, 198, 325, 249, 164, 212, 19, 61, 277, 238, 51, 149, 158, 253, 268, 193, 16, 284, 288, 176, 292, 263, 45, 169, 166, 123, 55, 32, 145, 181, 29, 276, 283, 84, 269, 92, 201, 69, 221, 174, 33, 107, 306, 101, 302, 50, 13, 273, 278, 82, 286, 9, 89, 58, 99, 95, 49, 144, 215, 76, 127, 75, 118, 165, 8, 229, 83, 150, 124, 148, 147, 192, 272, 184, 135, 37, 90]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kelis\\AppData\\Local\\Temp\\ipykernel_10472\\3275889473.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data[\"words\"][idx] = new_sent\n"
     ]
    }
   ],
   "source": [
    "p_sents = 0.2\n",
    "p_words = 0.3\n",
    "\n",
    "n_modified, idxs, perturbed_data = perturb_dataset(train_data, insert_multiple_letters, p_sents, p_words, prints=False)\n",
    "print(n_modified)\n",
    "print(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3337c285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>words</th>\n",
       "      <th>tags</th>\n",
       "      <th>tag_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[RT, @USER2362, :, Farmall, Heart, wOkxarf, Td...</td>\n",
       "      <td>[O, O, O, B-ORG, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[#Volunteeakodrvs, are, key, members, of, #CHE...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[@USErR2092ej, is, n't, fihtg, fguunnyy, how, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[RT, @USER80, :, Silence, igsf, better, than, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[I, just, spent, twenty, minutes, trycinekgd, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>1634</td>\n",
       "      <td>[RT, @USER1701, :, FT, ISLAND, -, I, Hope, (, ...</td>\n",
       "      <td>[O, O, O, O, B-PER, O, B-MISC, I-MISC, O, O, O...</td>\n",
       "      <td>[0, 0, 0, 0, 2, 0, 5, 7, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>1635</td>\n",
       "      <td>[@USER1321, @USER2526, Probably, ., He, is, n'...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>1636</td>\n",
       "      <td>[RT, @USER1920, :, @USER1260, @USER2624, it, '...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>1637</td>\n",
       "      <td>[You, have, that, right, ,, nor, do, they, int...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>1638</td>\n",
       "      <td>[RT, @USER364, :, Donald, Trump, is, the, Clea...</td>\n",
       "      <td>[O, O, O, B-PER, I-PER, O, O, O, O, O, O, O, B...</td>\n",
       "      <td>[0, 0, 0, 2, 4, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1639 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              words  \\\n",
       "0        0  [RT, @USER2362, :, Farmall, Heart, wOkxarf, Td...   \n",
       "1        1  [#Volunteeakodrvs, are, key, members, of, #CHE...   \n",
       "2        2  [@USErR2092ej, is, n't, fihtg, fguunnyy, how, ...   \n",
       "3        3  [RT, @USER80, :, Silence, igsf, better, than, ...   \n",
       "4        4  [I, just, spent, twenty, minutes, trycinekgd, ...   \n",
       "...    ...                                                ...   \n",
       "1634  1634  [RT, @USER1701, :, FT, ISLAND, -, I, Hope, (, ...   \n",
       "1635  1635  [@USER1321, @USER2526, Probably, ., He, is, n'...   \n",
       "1636  1636  [RT, @USER1920, :, @USER1260, @USER2624, it, '...   \n",
       "1637  1637  [You, have, that, right, ,, nor, do, they, int...   \n",
       "1638  1638  [RT, @USER364, :, Donald, Trump, is, the, Clea...   \n",
       "\n",
       "                                                   tags  \\\n",
       "0     [O, O, O, B-ORG, O, O, O, O, O, O, O, O, O, O,...   \n",
       "1     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "2                     [O, O, O, O, O, O, O, O, O, O, O]   \n",
       "3                           [O, O, O, O, O, O, O, O, O]   \n",
       "4      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "...                                                 ...   \n",
       "1634  [O, O, O, O, B-PER, O, B-MISC, I-MISC, O, O, O...   \n",
       "1635               [O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "1636                        [O, O, O, O, O, O, O, O, O]   \n",
       "1637  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "1638  [O, O, O, B-PER, I-PER, O, O, O, O, O, O, O, B...   \n",
       "\n",
       "                                                tag_idx  \n",
       "0     [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "3                           [0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "4      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "...                                                 ...  \n",
       "1634               [0, 0, 0, 0, 2, 0, 5, 7, 0, 0, 0, 0]  \n",
       "1635               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1636                        [0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1637  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1638  [0, 0, 0, 2, 4, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, ...  \n",
       "\n",
       "[1639 rows x 4 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perturbed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cfb2b932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(perturbed_data[\"words\"] == train_data[\"words\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
